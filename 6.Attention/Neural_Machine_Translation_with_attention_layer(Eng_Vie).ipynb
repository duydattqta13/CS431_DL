{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHBP5xzmrM4U",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8bc4640efacad5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# ATTENTION IN MACHINE LEARNING TRANSLATION\n",
    "## Dịch các câu từ tiếng Anh sang tiếng Việt với cơ chế Attention\n",
    "\n",
    "Trong bài tập trước, chúng ta đã làm quen và thực hành bài tập Dịch máy từ ngôn ngữ tiếng Anh sang tiếng Việt với sự hỗ trợ của mô hình Seq2Seq. Tuy nhiên, dễ thấy rằng, kết quả đánh giá hiệu năng thu được còn hạn chế.\n",
    "\n",
    "Vậy, làm thế nào để cải thiện khả năng dịch thuật của mô hình Dịch máy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5sIh9bcS-Ok",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c02ac88a9e39beb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=700 src=\"https://scontent.fsgn15-1.fna.fbcdn.net/v/t1.15752-9/335033530_123515087186693_2765806321722102319_n.png?_nc_cat=101&ccb=1-7&_nc_sid=ae9488&_nc_ohc=PmEE_PLZpYkAX-IiFiD&_nc_ht=scontent.fsgn15-1.fna&oh=03_AdTVSDAsOGxadp53fC0InRxLLhVJm5KVTfOjHYxRZjlVmA&oe=642F94B9\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th colspan=1>Minh họa sử dụng cơ chế Attention cho Encoder/Decoder.</th>\n",
    "<tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cơ chế Attention là một trong những giải pháp tiềm năng để giải quyết vấn đề này thông qua quá trình tập trung vào các vùng thông tin quan trọng để giúp mô hình học tốt hơn. Với cơ chế Attention, một \"từ\" có thể hiệu chỉnh được trọng số của nó cho các từ khác trong câu, sao cho các từ ở gần nó thì trọng số lớn hơn, ở xa nó thì trọng số nhỏ hơn. \n",
    "\n",
    "Mỗi \"câu\" sau khi đi qua bước embedding sẽ được biểu diễn dưới dạng một ma trận X(m, n) với m, n lần lượt thể hiện số từ và số chiều của mỗi vector từ được biểu diễn. Mô hình sẽ cần học được bộ trọng số (Wq, Wk, Wv) để thu được ma trận Q, K, V (Query, Key và Value). Ma trận Query và Key có tác dụng tính toán ra score cho các cặp từ. Ma trận Value sẽ dựa trên score để tính ra vector phân phối xác suất đầu ra. Hàm softmax được sử dụng để đưa giá trị score về một phân phối xác suất mà độ lớn sẽ đại diện cho mức độ attention của từ query và từ key. Như vậy mỗi một từ sẽ được biểu diễn bởi 3 vector Query, Key và Value. Bộ ba này sẽ thể hiện trọng số của mỗi từ với các từ còn lại trong câu. (Xem hình minh họa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=700 src=\"https://scontent.fsgn15-1.fna.fbcdn.net/v/t1.15752-9/335035086_1199463037552521_2920042504129337261_n.png?_nc_cat=107&ccb=1-7&_nc_sid=ae9488&_nc_ohc=MqlheVZ5DkcAX85qd-4&_nc_ht=scontent.fsgn15-1.fna&oh=03_AdRIMpW_IFpdIgXQjTADD9IbqM97fsM8EdJ3S7pKn1STYw&oe=642F6FDE\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th colspan=1>Minh họa kết quả tính toán attention cho từng từ trong câu. (Blog phamdinhkhanh)</th>\n",
    "<tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVPRC0bOtBas",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1d1804885216b14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Trong bài tập này, chúng ta sẽ tạo ra một mô hình LSTM encoder-decoder sử dụng [Keras Functional API](https://www.tensorflow.org/alpha/guide/keras/functional ( với [TensorFlow](https://www.tensorflow.org/) ). Sau đó, chúng ta thực hành chuyển đổi các câu tiếng Anh sang Tiếng Việt như bài tập lần trước. Sự khác biệt ở đây chính là chúng ta sẽ cài đặt thêm một Attention Head để cải thiện hiệu năng.\n",
    "\n",
    "Lưu ý: Sử dụng GPU để có thể huấn luyện mô hình nhanh hơn.\n",
    "\n",
    "Chúng ta cùng thực hiện các bước khởi tạo mô hình như bài tập lần trước nhé!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_r70epHozOt",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d64e0385d2c2b7db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq4aH4u1uq5V",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-30bfcc131f6e53a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1) Khai báo các thư viện\n",
    "\n",
    "Chúng ta sẽ khai báo TensorFlow và Keras. Từ Keras, chúng ta sẽ sử dụng các module khác để giúp xây dựng các lớp NN, tiền xử lý dữ liệu và xây dựng các mô hình LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qK2TWV1nm48Q",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f46f116d5fc79bb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import các thư viện cần thiết\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import pandas as pd\n",
    "from keras.models import load_model, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def fix_random_seed():\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnIg8HdTGW4o",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-766488d990fd3f70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2) Đọc dữ liệu\n",
    "\n",
    "\n",
    "Dữ liệu có hơn 9K cặp cụm từ English-Vietnamese. Bộ dữ liệu này có thể tải tại http://www.manythings.org/anki/. Hơn thế nữa, tại đây có hơn 50 bộ câu song ngữ. Chúng ta sẽ tải bộ dữ liệu cụm từ English-Vietnamese, giải nén và đọc bằng [Pandas](https://pandas.pydata.org/).\n",
    "\n",
    "**Server đã có sẵn dữ liệu này cho các bạn sử dụng, các bạn có thể sử dụng các lệnh dưới đây để tải và sử dụng dữ liệu trên các nền tảng khác.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27OzmS-MIymc",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d39d32e70c6497b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "09db0fca-3c3f-45fd-b717-a65f0bbdae0e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget http://www.manythings.org/anki/vie-eng.zip -O vie-eng.zip\n",
    "# !unzip vie-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK_-miCLPZvV",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-198faa27e708a97c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Sử dụng pandas để đọc dữ liệu và thêm tên cho các cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "QGmBbVVTrm74",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-89d0e438979b282e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "395518f6-71c5-497d-b97c-faa54c716a2f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28141/2228967803.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  lines = lines.drop( 'c' , 1 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>vie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Chạy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Chạy đi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Giúp tôi với!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Cứu tôi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump!</td>\n",
       "      <td>Nhảy đi!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eng            vie\n",
       "0   Run!          Chạy!\n",
       "1   Run!       Chạy đi!\n",
       "2  Help!  Giúp tôi với!\n",
       "3  Help!       Cứu tôi!\n",
       "4  Jump!       Nhảy đi!"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = None\n",
    "\n",
    "# TODO: đọc dữ liệu bằng `padas.read_table`, \n",
    "# gắn label cho 2 cột đầu là `eng` và `vie`,\n",
    "# loại bỏ cột cuối cùng\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "lines = pd.read_table('/data/cs2230/vie.txt' , names=['eng' , 'vie' , 'c' ] )\n",
    "lines = lines.drop( 'c' , 1 )\n",
    "# END SOLUTION\n",
    "\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwr1cuViqFZg",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c25d0d8186cd21e3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "09977b9d-1e04-41f4-afea-6033daceb9ba",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn đã qua bài test\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra với bộ test\n",
    "assert str(type(lines)) ==\"<class 'pandas.core.frame.DataFrame'>\" \n",
    "assert list(lines.columns) == ['eng' , 'vie']\n",
    "assert lines.shape == (9144, 2) \n",
    "assert lines.iloc[10]['eng']=='Hurry!'\n",
    "print('Bạn đã qua bài test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GWqenCnrqoYs",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1c7f9e67d4cd90f4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Kiểm tra với bộ test ẩn\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert str(type(lines)) ==\"<class 'pandas.core.frame.DataFrame'>\" \n",
    "assert list(lines.columns) == ['eng' , 'vie']\n",
    "assert lines.shape == (9144, 2) \n",
    "assert lines.iloc[10]['eng']=='Hurry!'\n",
    "index = [150, 200, 500]\n",
    "gt = [\"I don't know.\", 'Trust no one.', 'This car is his.']\n",
    "for i, gt in zip(index, gt):\n",
    "    assert lines.iloc[i]['eng']==gt\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dgIdfjIRLDN",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-973083836ca3d96a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3) Chuẩn bị dữ liệu đầu vào cho Encoder (`encoder_input_data`)\n",
    "Mô hình Encoder sẽ được cung cấp dữ liệu đầu vào là các câu tiếng Anh đã được tiền xử lý. \n",
    "Bước tiền xử lý được thực hiện như sau:\n",
    "\n",
    "Token hóa các câu tiếng Anh từ `eng_lines`.\n",
    "Xác định độ dài tối đa của câu tiếng Anh là `max_input_length`.\n",
    "Thêm vào `tokenized_eng_lines` để đạt đến `max_input_length`.\n",
    "Xác định kích thước từ vựng (`num_eng_tokens`) cho các từ tiếng Anh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2_ux1rZnDyY",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12a8e62e1c29fed5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "fc217d73-7fe0-4dec-d8ed-3f3d67a4f30b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ dài lớn nhất của English là 32\n",
      "Kích thước dữ liệu của Encoder  -> (9144, 32)\n",
      "Số lượng English tokens = 4054\n"
     ]
    }
   ],
   "source": [
    "eng_lines = list()\n",
    "for line in lines.eng:\n",
    "    eng_lines.append( line ) \n",
    "\n",
    "tokenizer = None\n",
    "tokenized_eng_lines = None\n",
    "max_input_length =  None\n",
    "\n",
    "# TODO: Sử dụng `preprocessing.text.Tokenizer` để biến đổi các câu thành các \n",
    "# tokens và lưu vào biến `tokenized_eng_lines`. Biến `max_input_length` lưu trữ\n",
    "# độ dài tối đa của các tokens.\n",
    "# Gợi ý: dùng 2 hàm là `fit_on_texts` và `texts_to_sequences`\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "eng_tokenizer = preprocessing.text.Tokenizer()\n",
    "eng_tokenizer.fit_on_texts( eng_lines ) \n",
    "tokenized_eng_lines = eng_tokenizer.texts_to_sequences( eng_lines ) \n",
    "max_input_length = np.array( [len( token_seq ) for token_seq in tokenized_eng_lines] ).max()\n",
    "# END SOLUTION\n",
    "\n",
    "# sử dụng pad_sequences để cố định kích thước input của encoder\n",
    "padded_eng_lines = preprocessing.sequence.pad_sequences( tokenized_eng_lines, maxlen=max_input_length , padding='post' )\n",
    "encoder_input_data = np.array( padded_eng_lines )\n",
    "\n",
    "eng_word_dict = eng_tokenizer.word_index\n",
    "num_eng_tokens = len( eng_word_dict )+1\n",
    "\n",
    "print( 'Độ dài lớn nhất của English là {}'.format( max_input_length ))\n",
    "print( 'Kích thước dữ liệu của Encoder  -> {}'.format( encoder_input_data.shape ))\n",
    "print( 'Số lượng English tokens = {}'.format( num_eng_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRwAd310SPkG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8825da111356c0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 4) Chuẩn bị dữ liệu đầu vào cho Decoder ( `decoder_input_data` )\n",
    "Mô hình decoder sẽ được cung cấp dữ liệu tiếng Việt đã được tiền xử lý. Các bước tiền xử lý giống như trên. Bước này được thực hiện trước các bước khác.\n",
    "\n",
    "Thêm nhãn `<START>` vào vị trí đầu tiên trong mỗi câu tiếng Việt.\n",
    "Thêm nhãn `<END>` vào vị trí cuối cùng trong mỗi câu tiếng Việt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deB0oX_0pj8R",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea4c3acf8c5ec878",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "b4fb5a0f-bb2e-4c84-c1a2-b5c31fb0ba21",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ dài lớn nhất của tiếng việt là 43\n",
      "kích thước dữ liệu đầu vào của Decoder -> (9144, 43)\n",
      "Số lượng Vietnamese tokens = 2478\n"
     ]
    }
   ],
   "source": [
    "vie_lines = list()\n",
    "# TODO: Khác với trên chúng ta phải thêm '<START> ' và ' <END>' vào \n",
    "# các câu tiếng Việt để tạo thành các dữ liệu đầu vào cho decoder\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "for line in lines.vie:\n",
    "    vie_lines.append( '<START> ' + line + ' <END>' )  \n",
    "# END SOLUTION\n",
    "\n",
    "tokenizer = None\n",
    "tokenized_vie_lines = None\n",
    "max_output_length = None\n",
    "\n",
    "# TODO: Tương tự như trên, chúng ta cũng sử dụng `preprocessing.text.Tokenizer` \n",
    "# để biến đổi các câu thành các tokens và lưu vào biến `tokenized_vie_lines`. \n",
    "# Biến `max_output_length` lưu trữ độ dài tối đa của các tokens.\n",
    "# Gợi ý: dùng 2 hàm là `fit_on_texts` và `texts_to_sequences`\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "vie_tokenizer = preprocessing.text.Tokenizer()\n",
    "vie_tokenizer.fit_on_texts( vie_lines ) \n",
    "tokenized_vie_lines = vie_tokenizer.texts_to_sequences( vie_lines ) \n",
    "max_output_length = np.array( [len( token_seq ) for token_seq in tokenized_vie_lines] ).max()\n",
    "# END SOLUTION\n",
    "\n",
    "# sử dụng pad_sequences để cố định kích thước output của decoder\n",
    "padded_vie_lines = preprocessing.sequence.pad_sequences( tokenized_vie_lines , maxlen=max_output_length, padding='post' )\n",
    "decoder_input_data = np.array( padded_vie_lines )\n",
    "vie_word_dict = vie_tokenizer.word_index\n",
    "num_vie_tokens = len( vie_word_dict )+1\n",
    "\n",
    "\n",
    "print( 'Độ dài lớn nhất của tiếng việt là {}'.format( max_output_length ))\n",
    "print( 'kích thước dữ liệu đầu vào của Decoder -> {}'.format( decoder_input_data.shape ))\n",
    "print( 'Số lượng Vietnamese tokens = {}'.format( num_vie_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFLjwXm9Snq0",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f6bbd9e4bbb5524e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "2815f514-265f-447b-8952-618a4c6fdc56",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn đã qua bài test\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra với bộ test\n",
    "assert num_eng_tokens == 4054\n",
    "assert num_vie_tokens == 2478\n",
    "assert decoder_input_data.shape == (9144, 43)\n",
    "assert encoder_input_data.shape == (9144, 32)\n",
    "assert tokenized_vie_lines[50:55] == [[1, 378, 2],\n",
    " [1, 11, 9, 14, 21, 3, 2],\n",
    " [1, 11, 9, 14, 21, 22, 2],\n",
    " [1, 1212, 57, 2],\n",
    " [1, 1212, 57, 18, 2]]\n",
    "assert tokenized_eng_lines[50:55] == [[52, 294], [52, 1462], \n",
    "                                      [52, 1462], [180, 137], [180, 137]]\n",
    "print('Bạn đã qua bài test')                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GeZPGIatTE_y",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-894b81eda9cd4871",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Kiểm tra với bộ test ẩn\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert num_eng_tokens == 4054\n",
    "assert num_vie_tokens == 2478\n",
    "assert decoder_input_data.shape == (9144, 43)\n",
    "assert encoder_input_data.shape == (9144, 32)\n",
    "\n",
    "assert tokenized_vie_lines[50:55] == [[1, 378, 2],\n",
    " [1, 11, 9, 14, 21, 3, 2],\n",
    " [1, 11, 9, 14, 21, 22, 2],\n",
    " [1, 1212, 57, 2],\n",
    " [1, 1212, 57, 18, 2]]\n",
    "assert tokenized_eng_lines[50:55] == [[52, 294], [52, 1462], \n",
    "                                      [52, 1462], [180, 137], [180, 137]]\n",
    "assert tokenized_vie_lines[10:20] == [[1, 271, 130, 2],\n",
    " [1, 271, 130, 39, 2],\n",
    " [1, 3, 16, 245, 2],\n",
    " [1, 3, 16, 245, 143, 69, 2],\n",
    " [1, 1840, 2],\n",
    " [1, 55, 18, 2],\n",
    " [1, 55, 42, 18, 2],\n",
    " [1, 157, 65, 2],\n",
    " [1, 113, 30, 2],\n",
    " [1, 96, 69, 2]]\n",
    "\n",
    "assert tokenized_eng_lines[80:90] == [[138, 13, 163],\n",
    " [57, 948],\n",
    " [50, 7, 59],\n",
    " [50, 7, 59],\n",
    " [50, 7, 59],\n",
    " [4, 1817],\n",
    " [4, 1817],\n",
    " [432, 48],\n",
    " [26, 2500],\n",
    " [17, 866]]\n",
    "\n",
    "assert tokenized_eng_lines[99:102] == [[1, 31, 1215], \n",
    "                                       [1, 31, 1818], \n",
    "                                       [1, 165, 48]]\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJTcSlygTQ_V",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bd882f192e54879",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 5) Chuẩn bị nhãn cho decoder ( decoder_target_data )\n",
    "\n",
    "Chúng ta sẽ lấy một bản sao của `tokenized_vie_lines` và sửa đổi nó như sau:\n",
    "\n",
    "1. Chúng ta sẽ xóa nhãn `<start>` mà chúng ta đã đính kèm trước đó. Vì vậy, từ `<start>` sẽ bị xóa.\n",
    "\n",
    "2. Chuyển đổi `padded_vie_lines` (những dòng không có nhãn `<start>`) sang các vector one-hot để huấn luyện mô hình.\n",
    "Ví dụ:\n",
    "\n",
    "```\n",
    " [ '<start>' , 'hello' , 'world' , '<end>' ]\n",
    "\n",
    "```\n",
    "\n",
    "sẽ trở thành\n",
    "\n",
    "```\n",
    " [ 'hello' , 'world' , '<end>' ]\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPCTmeL7qj3T",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c9281909c89941b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "bf774f5a-b4c6-4be2-d165-e90df5681a3b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder target data shape -> (9144, 43, 2478)\n"
     ]
    }
   ],
   "source": [
    "input_decoder_target_data = list()\n",
    "\n",
    "# TODO: chúng ta sẽ loại bỏ '<START> ' đầu tiên của các dòng trong biến `tokenized_vie_lines`\n",
    "# và thêm vào `input_decoder_target_data`\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "for token_seq in tokenized_vie_lines:\n",
    "    input_decoder_target_data.append( token_seq[ 1 : ] ) \n",
    "# END SOLUTION\n",
    "\n",
    "padded_vie_lines = preprocessing.sequence.pad_sequences(input_decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "onehot_vie_lines = utils.to_categorical( padded_vie_lines , num_vie_tokens )\n",
    "decoder_target_data = np.array( onehot_vie_lines )\n",
    "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nA6iDHbryuC",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-924aac61ce235adb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "79c4880b-1105-4c3d-d235-42faf58e58a8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn đã qua bài test\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra với bộ test\n",
    "assert decoder_target_data.shape==(9144, 43, 2478)\n",
    "# test remove start in decode_data\n",
    "for i in [5, 10, 15, 20]:\n",
    "    assert (sum(tokenized_vie_lines[i]) - sum(input_decoder_target_data[i])) == 1\n",
    "print('Bạn đã qua bài test')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Y_92urgOrSyz",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-494846e1230060d5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HIDDEN TESTS\n",
    "# Kiểm tra với bộ test ẩn\n",
    "assert decoder_target_data.shape==(9144, 43, 2478)\n",
    "assert (padded_vie_lines[50:52]==np.array([ \\\n",
    "    [378, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [11, 9, 14, 21, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],)).all() == True\n",
    "# test remove start in decode_data\n",
    "for i in range(lines.shape[0]):\n",
    "    assert (sum(tokenized_vie_lines[i]) - sum(input_decoder_target_data[i])) == 1\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KS5gWlcpFT1",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f52b2c23249189a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Định nghĩa và huấn luyện các mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_N71uykUPbe",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e4eec086ac65520",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1) Định nghĩa mô hình Encoder-Decoder\n",
    "\n",
    "Giống như bài trước, mô hình sẽ có các lớp Embedding, LSTM và Dense. Tuy nhiên,decoder sẽ có thêm lớp attention, cấu hình cơ bản như sau:\n",
    "\n",
    "* 2 lớp đầu vào: Một cho `encoder_input_data` và một cho `decoder_input_data`.\n",
    "* Lớp Embedding: Để chuyển đổi các vector token sang các dense có kích thước cố định = 256. ***(Lưu ý: để tham số `mask_zero=True`, `return_state=True`, `return_sequences=True`)***\n",
    "* Lớp LSTM: khởi tạo layer chứa 128 Long-Short Term cell.\n",
    "Hoạt động:\n",
    "\n",
    "1. `encoder_input_data` đầu vào lớp Embedding (`encoder_embedding`).\n",
    "2. Kết quả của lớp Embedding đi đến layer LSTM để tạo ra 2 vector trạng thái (`h` và `c` là `encoder_states`)\n",
    "3. Những trạng thái này được đưa vào trong layer LSTM của decoder.\n",
    "4. decoder_input_data đầu vào qua lớp Embedding.\n",
    "5. Embeddings đi vào lớp LSTM (mà có các trạng thái) để tạo các chuỗi.\n",
    "6. Các đầu ra của lớp LSTM sẽ đi qua lớp `AttentionLayer` do chúng ta định nghĩa trước khi vào lớp cuối cùng `Dense`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-SAvSJSauo5",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c7b26b2c42c4718",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Khác với bài trước chúng ta sẽ định nghĩa các module như encoder, decoder và attention từ lớp `tf.keras.layers.Layer` và sẽ thiết kế lớp Translator để kết hợp encoder và decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MKBJzClbT7rL",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61c13502da9ca5dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_eng_tokens, units=[256, 128]):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(num_eng_tokens, units[0], mask_zero=True)\n",
    "        self.lstm = tf.keras.layers.LSTM(units[1], return_state=True, return_sequences=True)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        # TODO: `x` sẽ được đi qua lớp 'self.embedding' và `self.lstm` đã tạo ra states và output.\n",
    "\n",
    "        # BEGIN SOLUTION\n",
    "        x = self.embedding(x)\n",
    "        x, state_h , state_c = self.lstm(x)\n",
    "        # END SOLUTION\n",
    "\n",
    "        return x, [state_h , state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QO8L4BnFATLx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e80e6590bb046514",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "082d3b61-cec0-4caf-f87b-f2de67efc363",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens, shape (batch, s): (8, 16)\n",
      "Encoder output, shape (batch, s, units): (8, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "# Chúng ta sẽ kiểm tra thử input và output của encoder thông qua đoạn code dưới\n",
    "x = tf.random.uniform(shape=[8, 16]) # random sample\n",
    "\n",
    "encoder = Encoder(num_eng_tokens)\n",
    "context, state = encoder(x)\n",
    "\n",
    "print(f'input tokens, shape (batch, s): {x.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {context.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KMVlI4DumMd",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9aefa89ecab44bfa",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "1b374626-33a2-43a3-c7fc-d76152820aa2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn đã qua bài test\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra với bộ test\n",
    "assert x.shape == (8, 16)\n",
    "assert context.shape == (8, 16, 128)\n",
    "assert state[0].shape == ([8, 128])\n",
    "print('Bạn đã qua bài test')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "x5XJOFS2umqh",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f79f44c233d58029",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HIDDEN TESTS\n",
    "# Kiểm tra với bộ test ẩn\n",
    "assert x.shape == (8, 16)\n",
    "assert context.shape == (8, 16, 128)\n",
    "assert len(state) == 2\n",
    "assert len(state[1]) == 8\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X03yPkGycg99",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-020570e36e026577",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Tiếp theo, chúng ta sẽ thiết kế `AttentionLayer` với `num_heads=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TcvDJkz2aNZU",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8373e10e4e052382",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, dim):\n",
    "    super().__init__()\n",
    "    # TODO: Chúng ta sẽ khởi tạo các thành phần trong `AttentionLayer` bao gồm `mha`, `layernorm` và `add` từ \n",
    "    # thư viện keras tf.keras.layers.MultiHeadAttention, tf.keras.layers.LayerNormalization, tf.keras.layers.Add\n",
    "\n",
    "    self.mha = None\n",
    "    self.layernorm = None\n",
    "    self.add = None\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=dim, num_heads=1)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    # END SOLUTION\n",
    "    \n",
    "  def call(self, x, context):\n",
    "\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "\n",
    "    self.last_attention_weights = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Je7yzRL2aPRa",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f898adaa8f136366",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "cd9ac24f-5fdc-472d-d592-4d982b2d2bc5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result, shape (batch, t, units): (8, 16, 512)\n",
      "Attention weights, shape (batch, t, s):    (8, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = AttentionLayer(256)\n",
    "\n",
    "x = tf.random.uniform(shape=[8, 16, 512])\n",
    "x_context = tf.random.uniform(shape=[8, 16, 512])\n",
    "\n",
    "result = attention_layer(x, x_context)\n",
    "\n",
    "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
    "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySyuTSqfvZmd",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1c69692d5bed5a71",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "25ea4cbd-bce7-406a-dca4-d291ee4e6ee1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn đã qua bài test\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra với bộ test\n",
    "assert result.shape == (8, 16, 512)\n",
    "assert attention_layer.last_attention_weights.shape == (8, 16, 16)\n",
    "print('Bạn đã qua bài test')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ynSphS7XvaD5",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-907048c13d32c009",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HIDDEN TESTS\n",
    "# Kiểm tra với bộ test ẩn\n",
    "assert result.shape == (8, 16, 512)\n",
    "assert attention_layer.last_attention_weights.shape == (8, 16, 16)\n",
    "\n",
    "assert attention_layer.weights[0].shape == ([512, 1, 256])\n",
    "assert len(attention_layer.weights) == 10\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "T4fWjLClaJoQ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd3dbc6a9e1f4b43",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_vie_tokens, units=[128, 256]):\n",
    "        super(Decoder, self).__init__()\n",
    "        # TODO: Chúng ta sẽ định nghĩa lớp `embedding`, `lstm`, `output_layer` \n",
    "        # từ các class 'Embedding', 'LSTM' và `Dense` của keras. \n",
    "        # `attention` được khởi tạo tù lớp `AttentionLayer` được định nghĩa trước đó\n",
    "        # Lưu ý: lớp `embedding`, `lstm` được khởi tạo giống như encoder\n",
    "\n",
    "        self.embedding = None\n",
    "        self.lstm = None\n",
    "        self.attention = None\n",
    "        self.output_layer = None\n",
    "\n",
    "        # BEGIN SOLUTION\n",
    "        self.embedding = tf.keras.layers.Embedding(num_vie_tokens, units[0], mask_zero=True)\n",
    "        self.lstm = tf.keras.layers.LSTM(units[1], return_state=True , return_sequences=True)\n",
    "        self.attention = AttentionLayer(units[1])\n",
    "        self.output_layer = tf.keras.layers.Dense(num_vie_tokens, activation=tf.keras.activations.softmax)\n",
    "        # END SOLUTION\n",
    "\n",
    "    def call(self,\n",
    "            context, x,\n",
    "            state=None,\n",
    "            return_state=False):  \n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x, state_h , state_c = self.lstm(x, initial_state=state)\n",
    "        x = self.attention(x, context)\n",
    "        output = self.output_layer(x)\n",
    "\n",
    "        if return_state:\n",
    "            return output, [state_h , state_c]\n",
    "        else:\n",
    "            return output\n",
    "    \n",
    "class Translator:\n",
    "    @classmethod\n",
    "    def add_method(cls, fun):\n",
    "        setattr(cls, fun.__name__, fun)\n",
    "        return fun\n",
    "\n",
    "    def __init__(self, num_eng_tokens, num_vie_tokens, units=[256, 128]):\n",
    "        self.encoder = Encoder(num_eng_tokens, units)\n",
    "        self.decoder = Decoder(num_vie_tokens, units)\n",
    "        self.num_eng_tokens = num_eng_tokens\n",
    "        self.num_vie_tokens = num_vie_tokens\n",
    "\n",
    "    def build(self):\n",
    "        encoder_inputs = tf.keras.layers.Input(shape=( None ,))\n",
    "        decoder_inputs = tf.keras.layers.Input(shape=( None ,))\n",
    "\n",
    "        context, states = self.encoder(encoder_inputs)\n",
    "        output = self.decoder(context, decoder_inputs, states)\n",
    "    \n",
    "        try:\n",
    "            # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "            del output._keras_mask\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        self.model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "\n",
    "    def train(self, encoder_input_data , decoder_input_data, decoder_target_data): \n",
    "        # Các hyper-parameter ở đây được chỉnh để có thể so sánh với mô hình trước.\n",
    "        # Nếu muốn, các bạn có thể tinh chỉnh để đạt hiệu suất cao hơn.\n",
    "        opt=tf.keras.optimizers.RMSprop(learning_rate=0.00256, momentum=0.9)\n",
    "        self.model.compile(optimizer=opt, loss='categorical_crossentropy') # CCE loss\n",
    "        self.model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=64, epochs=10) \n",
    "\n",
    "    # Load mô hình từ file\n",
    "    def load(self, model_file):\n",
    "        self.model = load_model(model_file)\n",
    "\n",
    "    # Lưu mô hình hiện tại xuống file\n",
    "    def save(self, model_file):\n",
    "        self.model.save(model_file)\n",
    "\n",
    "    # Tóm tắt kiến trúc mạng\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    # Thử nghiệm mô hình với dữ liệu ảnh đầu vào\n",
    "    def predict(self, x_test):\n",
    "        return self.model.predict(x_test)\n",
    "\n",
    "    def tokens_to_text(self, tokens):\n",
    "        words = self.id_to_word(tokens)\n",
    "        result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "        result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "        result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "smqHD6r18lXf",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76ae2c43f5ac64b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=[8, 16])\n",
    "x_context = tf.random.uniform(shape=[8, 16, 512])\n",
    "decoder = Decoder(2048, [128, 256])\n",
    "out = decoder(x_context, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNPo-wTSwIVU",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b3faed971a71bfeb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "6f5962ed-98f4-4be9-ff08-82b1150bad39",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn đã qua bài test\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra với bộ test\n",
    "assert out.shape == [8, 16, 2048]\n",
    "print('Bạn đã qua bài test')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Dr7zHWUGwIVV",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4750a4aac7ec460b",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HIDDEN TESTS\n",
    "# Kiểm tra với bộ test ẩn\n",
    "x_test = tf.random.uniform(shape=[4, 8])\n",
    "x_context_test = tf.random.uniform(shape=[4, 8, 512])\n",
    "decoder_test = Decoder(2048, [128, 256])\n",
    "out_test = decoder(x_context_test, x_test)\n",
    "\n",
    "assert out_test.shape == ([4, 8, 2048])\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7fg-7Lol6SAg",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-39270bbfb7cfbdbd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_random_seed()\n",
    "# TODO: Khởi tạo `alpha` từ class `Translator` được định nghĩa ở trên \n",
    "# và thực hiện phương thức `build` để xây dựng mô hình.\n",
    "\n",
    "alpha =None\n",
    "# BEGIN SOLUTION\n",
    "alpha = Translator(num_eng_tokens, num_vie_tokens)\n",
    "alpha.build()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ia5eKqo36ZPv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c01e01346951faff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "66b83dfc-de76-45ba-8022-2fc3e2f66c50",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_1 (Encoder)            ((None, None, 128),  1234944     ['input_1[0][0]']                \n",
      "                                 [(None, 128),                                                    \n",
      "                                 (None, 128)])                                                    \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_11 (Decoder)           (None, None, 2478)   1217454     ['encoder_1[0][0]',              \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'encoder_1[0][1]',              \n",
      "                                                                  'encoder_1[0][2]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,452,398\n",
      "Trainable params: 2,452,398\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alpha.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9g_8sR7WWf3",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ad7180068d4b2bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2) Huấn luyện mô hình\n",
    "Chúng ta sẽ huấn luyện mô hình với RMSprop optimizer và hàm cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmkn660K65Ef",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc1055547b9c84c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "f4be1804-643a-4e1c-8b2d-b85f51ef7bca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 05:51:43.159030: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3897319104 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 42s 209ms/step - loss: 4.6054\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 30s 207ms/step - loss: 3.3236\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 30s 212ms/step - loss: 2.6749\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 31s 216ms/step - loss: 2.2644\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 31s 220ms/step - loss: 1.9770\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 32s 221ms/step - loss: 1.7794\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 32s 223ms/step - loss: 1.6228\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 31s 218ms/step - loss: 1.5017\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 31s 215ms/step - loss: 1.4093\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 31s 217ms/step - loss: 1.3413\n"
     ]
    }
   ],
   "source": [
    "alpha.train(encoder_input_data , decoder_input_data, decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eeqv_vH5pMpb",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d031450923748305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Dự đoán kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4PAtzGrk8pq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52844c3d86ff8b7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1) Sử dụng mô hình để dự đoán\n",
    "Khác với bài trước, chúng ta sẽ thêm 2 hàm (`translate` và `plot_attention`) vào Translator để thực hiện các tác vụ dự đoán và trực quan hóa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "AipBUqiCKc_g",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-132f87827969b397",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_i2w = {val: key for key, val in vie_word_dict.items()}\n",
    "@Translator.add_method\n",
    "def translate(self, input, return_attention=False):\n",
    "    enc_model, dec_model = self.encoder, self.decoder\n",
    "    context, states_values = enc_model(input)\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = vie_word_dict['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = []\n",
    "    attentive_scores = []\n",
    "    while not stop_condition:\n",
    "        dec_outputs , [h , c] = dec_model(context, empty_target_seq, states_values, return_state=True)\n",
    "        attentive_scores.append(dec_model.attention.last_attention_weights[0])\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        word =  map_i2w.get(sampled_word_index, '')\n",
    "        decoded_translation.append( word )\n",
    "        sampled_word = word\n",
    "        if sampled_word == 'end' or len(decoded_translation) > max_output_length:\n",
    "            stop_condition = True\n",
    "\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "    if return_attention:\n",
    "        return decoded_translation[:-1], attentive_scores[:-1]\n",
    "\n",
    "    return decoded_translation[:-1]\n",
    "\n",
    "@Translator.add_method\n",
    "def plot_attention(self, text, **kwargs):\n",
    "    assert isinstance(text, str)\n",
    "    \n",
    "    input = eng_tokenizer.texts_to_sequences([text]) \n",
    "    input = preprocessing.sequence.pad_sequences(input, maxlen=max_input_length , padding='post' )\n",
    "    output, attention = self.translate(input, return_attention=True)\n",
    "    attention= tf.concat(attention, 0)\n",
    "\n",
    "    context = text.split()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    ax.set_xlabel('Input text')\n",
    "    ax.set_ylabel('Output text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djEPrfJBmZE-",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32530e35726433a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2) Thực hiện một số bản dịch\n",
    "\n",
    "1. Đầu tiên, sử dụng `enc_model` để dự đoán các giá trị trạng thái cho một câu tiếng Anh.\n",
    "2. Thiết lập các giá trị trạng thái trong LSTM của decoder.\n",
    "3. Sau đó, tạo ra một dãy có chứa phần tử `<start>`.\n",
    "4. Nhập dãy này vào `dec_model`.\n",
    "5. Thay thế phần tử `<start>` với phần tử được dự đoán bởi `dec_model` và  cập nhật các giá trị trạng thái.\n",
    "6. Thực hiện các bước trên liên tục cho đến khi gặp phần tử `<end>` hoặc đạt đến độ dài tối đa của chuỗi.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY5ogEHMOy6T",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-966a24b0689714c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "1b755e6d-1c22-4a34-9dda-1f0f6bf09275",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [03:44<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "enc_model , dec_model = alpha.encoder, alpha.decoder\n",
    "num_sample = encoder_input_data.shape[0]\n",
    "predict_translation = []\n",
    "eng_sentence = []\n",
    "num_sample = 800\n",
    "for i in tqdm(range( num_sample ) ):\n",
    "    decoded_translation = alpha.translate(encoder_input_data[ i ][None,...])\n",
    "    eng_sentence.append(encoder_input_data[ i ])\n",
    "    predict_translation.append( decoded_translation[:-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "EoiDqeChWT37",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab1256e29de1e075",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "value2key = {val:key for key, val in vie_tokenizer.word_index.items()}\n",
    "gt = [[[value2key[i] for i in line[1:-1]]] for line in tokenized_vie_lines[:num_sample]]\n",
    "predict = [f for f in predict_translation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xLMVz55Q6WD",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-523c5d8900d4ec1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "760f5d67-c598-4578-d114-b74114408d52",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: Really?, predict: ['thật', 'sự', 'thật', 'sự'], label: ['thật', 'á']\n",
      "input: It's cold., predict: ['đó', 'là', 'lạnh'], label: ['lạnh']\n",
      "input: I guess so., predict: ['tôi', 'đoán'], label: ['tôi', 'đoán', 'vậy']\n"
     ]
    }
   ],
   "source": [
    "for i in [20, 50, 70]:\n",
    "    print(f'input: {eng_lines[i]}, predict: {predict[i]}, label: {gt[i][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1nTBeGSecmnM",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4632eb3cf71194df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(predict) == len(gt), f'{len(predict)}, {len(gt)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "h7XX6v8FPayk",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2315e01af016b115",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict = [f for f in predict_translation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7wPSxGGPO6T",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-69793e79f748c0de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4c6a246c-9125-4670-f036-6b6d2d6d93ba",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giá trị bleu score là 0.5340076300042356\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "# references = [[['this', 'is' 'cat']]]\n",
    "# candidates = [['this', 'is', 'a', 'cat'],]\n",
    "references = gt\n",
    "candidates = predict\n",
    "score = corpus_bleu(references, candidates, weights=(1, 0, 0, 0))\n",
    "print('giá trị bleu score là', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6b8BKP-m5S5",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4760aab7d3c85157",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "39ba944d-d6ed-4d29-c935-3a4dfd7a98aa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giá trị bleu score đạt khoảng 0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "your_choice = None\n",
    "# ví dụ: 0.85 được hiểu là 0.9 còn 0.84 được hiểu là 0.8\n",
    "scores = np.arange(0,1,0.1)\n",
    "# BEGIN SOLUTION\n",
    "your_choice = 6 # 0.5682108719092033 \n",
    "# END SOLUTION\n",
    "print('giá trị bleu score đạt khoảng', scores[your_choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "gH52_gSxn1JS",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-da8f2d308680dba2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HIDDEN TESTS\n",
    "# Kiểm tra với bộ test ẩn\n",
    "assert your_choice in [5, 6, 4, 7]\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SA6mEssKdL9g",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3de1c1f971328164",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "d741cef0-606f-4da4-d3d1-c4911cb18de4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So với seq2seq, mô hình seq2seq với attention đạt hiệu suất  cao hơn\n"
     ]
    }
   ],
   "source": [
    "your_choice = None\n",
    "answers = {\n",
    "    1: 'cao hơn', \n",
    "    2: 'ngang bằng',\n",
    "    3: 'thấp hơn',\n",
    "}\n",
    "# BEGIN SOLUTION\n",
    "your_choice = 1\n",
    "# END SOLUTION\n",
    "print('So với seq2seq, mô hình seq2seq với attention đạt hiệu suất ', answers[your_choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "fDKWLJCQdwO_",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dd691aa3a0bc3ee0",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEGIN HIDDEN TESTS\n",
    "# Kiểm tra với bộ test ẩn\n",
    "assert your_choice == 1\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT1-iWd3-GVm",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b7b9e836f0e7851c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Chúng ta có thể kiểm tra và trực quan hóa attention map bằng cách nhập các câu tiếng anh vào biến `human_input`. \n",
    "\n",
    "Lưu ý: ô này không tính điểm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "RSmjd3tpQjp4",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fbc1f0991893540b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "9da7a92e-fc7c-44a7-e044-ac0adc3b47b4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28141/2050953749.py:48: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_28141/2050953749.py:49: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_input = 'i like apple'\n",
    "try: \n",
    "    alpha.plot_attention(human_input)\n",
    "except Exception as err:\n",
    "    print(f\"Unexpected {err=}, {type(err)=}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
